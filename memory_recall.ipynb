{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "memory-recall.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXBtql_QlgwB"
      },
      "source": [
        "# Fundamental Law of Memory Recall \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2SxB0rVHSUt"
      },
      "source": [
        "## Load packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "655c1YUFCJxQ"
      },
      "source": [
        "#!sudo apt-get install texlive-full  "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MgYBXMErB0w"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import seaborn as sns\n",
        "import scipy\n",
        "from matplotlib import cm\n",
        "import random\n",
        "import heapq\n",
        "from collections import Counter\n",
        "import scipy as sp\n",
        "\n",
        "#plt.rc('text', usetex=True)\n",
        "#plt.rc('font', family='serif')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lG6-M4uHVxS"
      },
      "source": [
        "## Model explanation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nWetz8hmEKG"
      },
      "source": [
        "Item representations are chosen as random binary $\\{0,1\\}$ vectors where each element of the vector chosen to be 1 with small probability $f \\ll 1$ independently of other elements.\n",
        "Overlaps are defined as scalar products between these\n",
        "representations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78pTU0WkmCe5"
      },
      "source": [
        "The proposed recall process is based on two principles:\n",
        "\n",
        "1. memory items are represented in the brain by overlapping random sparse neuronal ensembles in dedicated memory networks;\n",
        "2. the next item to be recalled is the one with a largest overlap to the current one, excluding the item that was recalled on the previous step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DckOZqNk4DZg"
      },
      "source": [
        "Pseudocode:\n",
        "- find the second largest value in the first row of SM\n",
        "- go to the row corresponding to its column index\n",
        "- iterate \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd-x8eMNHOhf"
      },
      "source": [
        "## Define the functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN4oL_QAmeYW"
      },
      "source": [
        "def BuildItems(L, N, f): \n",
        "    \"\"\"\n",
        "    L = number of items\n",
        "    N = number of neurons\n",
        "    f = probability of a neuron to be 1\n",
        "    \"\"\"\n",
        "    np.random.seed(5) # good example with seed = 5, L = 5, N = 3000, f = 0.1\n",
        "    return np.random.choice([0, 1], size=(N, L), p=[1-f, f])\n",
        "\n",
        "def SparseRandomEnsemble(L, N, f):\n",
        "    items = sp.sparse.random(N, L, density=f).A\n",
        "    for i in range(N):\n",
        "        for j in range(L):\n",
        "            if items[i,j] != 0:\n",
        "                items[i,j] = 1\n",
        "    return items\n",
        "\n",
        "def SimilarityMatrix(items):\n",
        "    #sim = cosine_similarity(items, dense_output=True)\n",
        "    sim = np.dot(items.T, items)\n",
        "    # change the diagonal elements from 0 to 1 so that it does not interfere when we are\n",
        "    # searching for the maximum element in a row\n",
        "    np.fill_diagonal(sim, 0)\n",
        "    return sim \n",
        "\n",
        "def PlotSM(sim, L):\n",
        "    sns.set_context({\"figure.figsize\": (12, 12)})\n",
        "    sns.set_style(\"white\")\n",
        "    fig = plt.figure()\n",
        "    ax1 = fig.add_subplot(111)\n",
        "    cmap = cm.get_cmap('Blues', 20)\n",
        "    cmap.set_bad('w') # default value is 'k'\n",
        "    ax1.imshow(sim, cmap=cmap)\n",
        "    #plt.ylabel(\"Cluster\", size = L)\n",
        "    #plt.xlabel(\"Cluster\", size = L)\n",
        "    sns.despine()\n",
        "    plt.colorbar(ax1.matshow(sim, cmap=cmap), shrink=.75)\n",
        "    ax1.xaxis.set_label_position('bottom')\n",
        "    ax1.xaxis.set_ticks_position('bottom')\n",
        "    plt.xticks(range(0,L,1), size = L)\n",
        "    plt.yticks(range(0,L,1), size = L)\n",
        "    #plt.savefig('similarity_matrix.pdf', dpi=220, bbox_inches='tight')\n",
        "\n",
        "def memory_recall_process(L, N, f, vb=False):\n",
        "    items = BuildItems(L, N, f)\n",
        "    sim = SimilarityMatrix(items)\n",
        "    if vb == True: \n",
        "        print(sim)\n",
        "    recall_list = []\n",
        "    recall_list.append(0)\n",
        "    recall_list.append(np.where(sim[0, ] == sim[0, ].max())[0][0])\n",
        "    for i in range(1, L**2): \n",
        "        #if vb == True:\n",
        "        #    print(\"Recall list =\", recall_list)\n",
        "        recall_list.append(np.where(sim[recall_list[i], ] == sim[recall_list[i], ].max())[0][0])\n",
        "        if (sim[recall_list[i-1], recall_list[i]] == sim[recall_list[i], recall_list[i+1]]):\n",
        "            sl = heapq.nlargest(2, sim[recall_list[i], ])\n",
        "            if sl[0] == sl[1]:\n",
        "                recall_list[i+1] = np.where(sim[recall_list[i], ] == sl[1])[0][1]\n",
        "            else:\n",
        "                recall_list[i+1] = np.where(sim[recall_list[i], ] == sl[1])[0][0]\n",
        "        ############################################################################################\n",
        "        # INSERT A CONDITION FOR STOPPING HERE:\n",
        "        # if two previously visited items are retrieved in the same order then stop.\n",
        "        ############################################################################################\n",
        "    R = len(set(recall_list))\n",
        "    return R\n",
        "\n",
        "def TheoreticalScaling(L):\n",
        "    return np.sqrt(1.5*np.pi*float(L))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_odk4lApHeOq"
      },
      "source": [
        "## Run a small test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09xblh6S50II",
        "outputId": "3f77360c-189d-4bcd-cb9b-f17026e413e1"
      },
      "source": [
        "r = memory_recall_process(10, 3000, 0.1, vb = True)\n",
        "r\n",
        "# [0, 4, 9, 7, 2, 5, 3, 8, 6, 9] for random_seed=5"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0 27 31 33 38 24 32 33 30 31]\n",
            " [27  0 29 27 28 31 27 26 26 26]\n",
            " [31 29  0 29 29 33 33 40 28 27]\n",
            " [33 27 29  0 25 36 29 32 34 30]\n",
            " [38 28 29 25  0 30 24 30 28 37]\n",
            " [24 31 33 36 30  0 28 27 18 25]\n",
            " [32 27 33 29 24 28  0 28 36 34]\n",
            " [33 26 40 32 30 27 28  0 31 37]\n",
            " [30 26 28 34 28 18 36 31  0 23]\n",
            " [31 26 27 30 37 25 34 37 23  0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBwmtv71Hgao"
      },
      "source": [
        "## Do the actual computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROdNail9wUzj"
      },
      "source": [
        "N = 3000\n",
        "f_val = [0.1, 0.05, 0.01]\n",
        "L_val = [10, 20, 50, 80, 130, 280, 500]\n",
        "\n",
        "nruns = 100\n",
        "\n",
        "R_f01_L10 =  0\n",
        "R_f01_L20 =  0\n",
        "R_f01_L50 =  0 \n",
        "R_f01_L80 =  0\n",
        "R_f01_L130 = 0\n",
        "R_f01_L280 = 0\n",
        "R_f01_L500 = 0 \n",
        "\n",
        "R_f005_L10 =  0\n",
        "R_f005_L20 =  0\n",
        "R_f005_L50 =  0\n",
        "R_f005_L80 =  0\n",
        "R_f005_L130 = 0\n",
        "R_f005_L280 = 0\n",
        "R_f005_L500 = 0 \n",
        "\n",
        "R_f001_L10 =  0\n",
        "R_f001_L20 =  0\n",
        "R_f001_L50 =  0 \n",
        "R_f001_L80 =  0\n",
        "R_f001_L130 = 0\n",
        "R_f001_L280 = 0\n",
        "R_f001_L500 = 0 \n",
        "\n",
        "for run in range(nruns):\n",
        "    print(\"run \", run)\n",
        "    print(\"f=0.1\")\n",
        "    R_f01_L10  = R_f01_L10  + memory_recall_process(L_val[0], N, f_val[0])\n",
        "    R_f01_L20  = R_f01_L20  + memory_recall_process(L_val[1], N, f_val[0])\n",
        "    R_f01_L50  = R_f01_L50  + memory_recall_process(L_val[2], N, f_val[0])\n",
        "    R_f01_L80  = R_f01_L80  + memory_recall_process(L_val[3], N, f_val[0])\n",
        "    R_f01_L130 = R_f01_L130 + memory_recall_process(L_val[4], N, f_val[0])\n",
        "    R_f01_L280 = R_f01_L280 + memory_recall_process(L_val[5], N, f_val[0])\n",
        "    R_f01_L500 = R_f01_L500 + memory_recall_process(L_val[6], N, f_val[0])\n",
        "    print(\"f=0.05\")\n",
        "    R_f005_L10  = R_f005_L10  + memory_recall_process(L_val[0], N, f_val[1])\n",
        "    R_f005_L20  = R_f005_L20  + memory_recall_process(L_val[1], N, f_val[1])\n",
        "    R_f005_L50  = R_f005_L50  + memory_recall_process(L_val[2], N, f_val[1])\n",
        "    R_f005_L80  = R_f005_L80  + memory_recall_process(L_val[3], N, f_val[1])\n",
        "    R_f005_L130 = R_f005_L130 + memory_recall_process(L_val[4], N, f_val[1])\n",
        "    R_f005_L280 = R_f005_L280 + memory_recall_process(L_val[5], N, f_val[1])\n",
        "    R_f005_L500 = R_f005_L500 + memory_recall_process(L_val[6], N, f_val[1])\n",
        "    print(\"f=0.01\")\n",
        "    R_f001_L10  = R_f001_L10  + memory_recall_process(L_val[0], N, f_val[2])\n",
        "    R_f001_L20  = R_f001_L20  + memory_recall_process(L_val[1], N, f_val[2])\n",
        "    R_f001_L50  = R_f001_L50  + memory_recall_process(L_val[2], N, f_val[2])\n",
        "    R_f001_L80  = R_f001_L80  + memory_recall_process(L_val[3], N, f_val[2])\n",
        "    R_f001_L130 = R_f001_L130 + memory_recall_process(L_val[4], N, f_val[2])\n",
        "    R_f001_L280 = R_f001_L280 + memory_recall_process(L_val[5], N, f_val[2])\n",
        "    R_f001_L500 = R_f001_L500 + memory_recall_process(L_val[6], N, f_val[2])\n",
        "\n",
        "R_f01  = [R_f01_L10 , R_f01_L20 , R_f01_L50 , R_f01_L80 , R_f01_L130 , R_f01_L280 , R_f01_L500]\n",
        "R_f005 = [R_f005_L10, R_f005_L20, R_f005_L50, R_f005_L80, R_f005_L130, R_f005_L280, R_f005_L500]\n",
        "R_f001 = [R_f001_L10, R_f001_L20, R_f001_L50, R_f001_L80, R_f001_L130, R_f001_L280, R_f001_L500]\n",
        "\n",
        "R_f01  = [elem / nruns for elem in R_f01]\n",
        "R_f005 = [elem / nruns for elem in R_f005]\n",
        "R_f001 = [elem / nruns for elem in R_f001]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf3FsGr0Hn5v"
      },
      "source": [
        "## Plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN1YlRddTo5-"
      },
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "plt.xlabel(\"List length\")\n",
        "plt.ylabel(\"Retrieved items (mean)\")\n",
        "plt.grid()\n",
        "rlist = [R_f01, R_f005, R_f001]\n",
        "plt.plot(L_val, [TheoreticalScaling(val) for val in L_val], '--', label='$\\sqrt{3\\pi L/2}$')\n",
        "for r in range(3):\n",
        "    plt.plot(L_val, rlist[r], 'o-', label='$f = '+str(f_val[r])+'$') \n",
        "plt.legend()\n",
        "plt.savefig('symmetricSM.pdf', bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWcqdghHTo_t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8HVY5zFc6ya"
      },
      "source": [
        "## Backup & old code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGVFlj3cdBeF"
      },
      "source": [
        "The very first version of the `memory_recall_process` function.\n",
        "```\n",
        "def memory_recall_process_OLD(L, N, f):\n",
        "    items = BuildItems(L, N, f)\n",
        "    sim = SimilarityMatrix(items)\n",
        "    # starting point: find the largest element in the first row\n",
        "    recall_list = [None]*(L+1)\n",
        "    recall_list[0] = np.where(sim[0, ] == sim[0, ].max())[0][0]\n",
        "    for i in range(L):\n",
        "        # find the largest element in a row\n",
        "        recall_list[i+1] = np.where(sim[recall_list[i], ] == sim[recall_list[i], ].max())[0][0]\n",
        "        # if the process points to an item that was just recalled in the previous step,\n",
        "        # select the next largest overlap \n",
        "        if recall_list[i+1] == recall_list[i]:\n",
        "            sl = heapq.nlargest(2, sim[recall_list[i], ])\n",
        "            recall_list[i+1] = np.where(sim[recall_list[i], ] == sl[1])[0][0]\n",
        "    R = len(set(recall_list))\n",
        "    return R\n",
        "```\n",
        "\n",
        "Memory recall process starting from a random similarity matrix. Useless. \n",
        "```\n",
        "def RandomSM_memory_recall_process(L):\n",
        "    sim = np.random.rand(L, L)\n",
        "    np.fill_diagonal(sim, 0)\n",
        "    recall_list = [None]*(L+1)\n",
        "    recall_list[0] = np.where(sim[0, ] == sim[0, ].max())[0][0]\n",
        "    recall_list[1] = np.where(sim[recall_list[0], ] == sim[recall_list[0], ].max())[0][0]\n",
        "    if sim[recall_list[1], recall_list[0]] == sim[recall_list[0], recall_list[1]]:\n",
        "        sl = heapq.nlargest(2, sim[recall_list[0], ])\n",
        "        recall_list[1] = np.where(sim[recall_list[0], ] == sl[1])[0][0]\n",
        "    for i in range(1, L):\n",
        "        # find the largest element in a row\n",
        "        recall_list[i+1] = np.where(sim[recall_list[i], ] == sim[recall_list[i], ].max())[0][0]\n",
        "        # if the process points to an item that was just recalled in the previous step,\n",
        "        # select the next largest overlap \n",
        "        if sim[recall_list[i-1], recall_list[i]] == sim[recall_list[i], recall_list[i+1]]:\n",
        "            sl = heapq.nlargest(2, sim[recall_list[i], ])\n",
        "            recall_list[i+1] = np.where(sim[recall_list[i], ] == sl[1])[0][0]\n",
        "    R = len(set(recall_list))\n",
        "    return R\n",
        "```\n",
        "\n",
        "This is the old `memory_recall_process`, in which the `recall_list` array is allocated at the beginning, which for sure is not the best solution. \n",
        "```\n",
        "def memory_recall_process(L, N, f):\n",
        "    items = BuildItems(L, N, f)\n",
        "    sim = SimilarityMatrix(items)\n",
        "    print(sim)\n",
        "    recall_list = [None]*(L**2)\n",
        "    # always start from the first item\n",
        "    recall_list[0] = 0\n",
        "    # pick the most similar item to the first \n",
        "    recall_list[1] = np.where(sim[0, ] == sim[0, ].max())[0][0]\n",
        "    #recall_list[2] = np.where(sim[recall_list[0], ] == sim[recall_list[0], ].max())[0][0]\n",
        "    #if sim[recall_list[1], recall_list[0]] == sim[recall_list[0], recall_list[1]]:\n",
        "    #    sl = heapq.nlargest(2, sim[recall_list[0], ])\n",
        "    #    recall_list[1] = np.where(sim[recall_list[0], ] == sl[1])[0][0]\n",
        "    for i in range(1, L):\n",
        "        print(\"Recall list =\", recall_list)\n",
        "        # find the largest element in a row\n",
        "        recall_list[i+1] = np.where(sim[recall_list[i], ] == sim[recall_list[i], ].max())[0][0]\n",
        "        #print(\"i+1 before check\", recall_list[i+1])\n",
        "        # if the process points to an item that was just recalled in the previous step,\n",
        "        # select the next largest overlap \n",
        "        #print(\"recall first:\", recall_list[i+1])\n",
        "        #print(\"if\", recall_list[i+1], \"==\", recall_list[i])\n",
        "        #print(sim[recall_list[i-1], recall_list[i]], \"==\", sim[recall_list[i], recall_list[i+1]])\n",
        "        if (sim[recall_list[i-1], recall_list[i]] == sim[recall_list[i], recall_list[i+1]]):\n",
        "            sl = heapq.nlargest(2, sim[recall_list[i], ])\n",
        "            if sl[0] == sl[1]:\n",
        "                #print(\"We have a problem...\")\n",
        "                #print(\"here:\", np.where(sim[recall_list[i], ] == sl[1])[0][1])\n",
        "                recall_list[i+1] = np.where(sim[recall_list[i], ] == sl[1])[0][1]\n",
        "            else:\n",
        "                recall_list[i+1] = np.where(sim[recall_list[i], ] == sl[1])[0][0]\n",
        "            #print(\"after check:\", recall_list[i+1])\n",
        "    R = len(set(recall_list))\n",
        "    return R\n",
        "```\n",
        "\n"
      ]
    }
  ]
}